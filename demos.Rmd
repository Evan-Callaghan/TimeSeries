---
title: "Neural Network Imputer Demonstration"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r imputer_functions, include=FALSE}
## Defining all functions
## -----------------------


#' initialize
#' 
#' Function to initialize the imputation process. Completes the first step of the designed algorithm 
#' which is to linearly impute the missing values as a starting point.
#' @param x0 {list}; List object containing the original incomplete time series
#' 
initialize_demo <- function(x0){
  gapTrue = ifelse(is.na(x0), NA, TRUE) ## Identifying gap structure
  blocks = tsinterp::findBlocks(gapTrue) ## Computing block structure
  xI = tsinterp::linInt(x0, blocks) ## Initial imputation using linear interpolation
  return(xI)
}


#' estimator
#' 
#' Function to estimate the trend and periodic components of a given time series. Completes the second 
#' step of the designed algorithm.
#' @param x {list}; List object containing a complete time series
#' 
estimator_demo <- function(x, main_demo = FALSE){
  Mt = estimateMt(x = x, N = length(x), nw = 5, k = 8, pMax = 2) ## Estimating trend component
  Tt = estimateTt(x = x - Mt, epsilon = 1e-6, dT = 1, nw = 5, k = 8, sigClip = 0.999) ## Estimating periodic components
  Xt = Mt
  for (i in 1:dim(Tt)[2]){
    Xt = Xt + Tt[,i]
  }
  if (main_demo == TRUE){
    return(Xt)
  }
  else{
    return(list(Mt, Tt, Xt))
    }
}


#' preprocess
#' 
#' Function to preprocess the data before building the neural network imputer. The function performs 0-1
#' standardization for each time series in the input matrix and masks NA values with 0 (necessary for 
#' the neural network).
#' @param inputs {matrix}; Matrix object containing a time series in each row (includes NAs)
#' @param targets {matrix}; Matrix object containing a time series in each row (excludes NAs)
#' 
preprocess_demo <- function(inputs, targets){
  for (i in 1:dim(inputs)[1]){
    inputs[i,] = (inputs[i,] - min(targets[i,])) / (max(targets[i,]) - min(targets[i,])) 
    targets[i,] = (targets[i,] - min(targets[i,])) / (max(targets[i,]) - min(targets[i,]))
  }
  return(list(inputs, targets))
}


#' simulator
#' 
#' Function to simulate a number of time series with on slight perturbations given the estimated
#' structure of the original time series. With each new series, a specified gap structure is 
#' imposed and returned are two data matrices: one with missing gaps (inputs) and one that is
#' complete (targets). Completes the third and fourth steps of the designed algorithm.
#' @param x0 {list}; List object containing the original gappy time series 
#' @param x {list}; List object containing a complete time series 
#' @param w {list}; List object containing a complete time series of residual noise
#' @param n_series {integer}; Number of new time series to construct
#' @param p {flaot}; Proportion of missing data to be applied to the simulated series
#' @param g {integer}; Gap width of missing data to be applied to the simulated series
#' @param K {integer}; Number of output series with a unique gap structure for each simulated series
#' @param random {boolean}; Whether or not to apply random indexing for gap structure (default: TRUE)
#' 
simulator_demo <- function(x0, x, w, n_series, p, g, K, random = TRUE){
  if (random == FALSE){K = 1}
  N = length(x); M = n_series * K ## Defining useful parameters
  inputs_temp = c(); targets_temp = c() ## Initializing vectors to store values
  w = fft(w, inverse = FALSE) ## Converting noise to frequency domain
  
  if (random == TRUE){
    for (i in 1:n_series){
      w_p = w * complex(modulus = runif(N, 0.98, 1.02), argument = runif(N, -pi/6, -pi/6)) ## Creating small perturbation
      w_t = as.numeric(fft(w_p, inverse = TRUE)) / N ## Converting back to time domain
      x_p = x + w_t ## Adding perturbed noise back to trend and periodic
      x_g = simulateGaps(list(x_p), p = p, g = g, K = K) ## Imposing gap structure
      
      for (k in 1:K){
        structure = paste0('x_g[[1]]$p', p, '$g', g, '[[k]]')
        inputs_temp = c(inputs_temp, eval(parse(text = structure))) ## Appending inputs
        targets_temp = c(targets_temp, x_p) ## Appending targets
      }
    }
  }
  
  else if (random == FALSE){
    g_index = which(is.na(x0)) ## Defining useful parameters
    for (i in 1:n_series){
      w_p = w * complex(modulus = runif(N, 0.98, 1.02), argument = runif(N, -pi/6, -pi/6)) ## Creating small perturbation
      w_t = as.numeric(fft(w_p, inverse = TRUE)) / N ## Converting back to time domain
      x_p = x + w_t ## Adding perturbed noise back to trend and periodic
      x_g = x_p; x_g[g_index] = NA ## Imposing non-randomized gap structure
      inputs_temp = c(inputs_temp, x_g) ## Appending inputs
      targets_temp = c(targets_temp, x_p) ## Appending targets
    }
  }
  
  inputs = array(matrix(inputs_temp, nrow = M, byrow = TRUE), dim = c(M, N)) ## Properly formatting inputs
  targets = array(matrix(targets_temp, nrow = M, byrow = TRUE), dim = c(M, N)) ## Properly formatting targets
  preprocessed = preprocess_demo(inputs, targets) ## Preprocessing
  inputs = preprocessed[[1]]; targets = preprocessed[[2]]
  return(list(inputs, targets))
}




## ------------------------------
## Need to update:





#' impute
#' 
#' Function to construct, compile, and fit a neural network model on the simulated training data
#' and then predict on the original time series. Completes the fifth step of the designed algorithm.
#' @param x0 {list}; List object containing the original incomplete time series
#' @param inputs {matrix}; Matrix object containing the input training data
#' @param targets {matrix}; Matrix object containing the target training data
#' 
impute_demo <- function(x0, inputs, targets, return_model = FALSE){
  N = dim(inputs)[2] ## Defining useful parameters
  x0 = as.array(matrix(ifelse(is.na(x0), 0, x0), nrow = 1, byrow = TRUE)) ## Formatting original series
  
  autoencoder = keras_model_sequential(name = 'Autoencoder') %>% ## Constructing the model
    layer_masking(mask_value = 0, input_shape = c(N), name = 'mask') %>%
    layer_dense(units = 32, activation = 'relu', name = 'encoder') %>%
    layer_dense(units = N, activation = 'sigmoid', name = 'decoder') 
  
  autoencoder %>% compile( ## Compiling the model
    optimizer = 'adam',
    loss = 'binary_crossentropy')
  
  if (return_model == TRUE){
    print(autoencoder)
    return(autoencoder)
  }
  
  autoencoder %>% fit(inputs, targets, epochs = 25, batch_size = 32, ## Fitting the model to the training data
                      shuffle = TRUE, validation_split = 0.2, verbose = 0)
  
  preds = autoencoder %>% predict(x0, verbose = 0) ## Predicting on the original series
  return(preds)
}


## Defining all copied functions from TSinterp
## -----------------------

## Defining function to estimate trend component
estimateMt <- function(x, N, nw, k, pMax) {
  V <- dpss(n = N, nw = 5, k = 8)$v
  test <- dpssap(V, pMax) # fit quadratic
  U <- test[[1]]
  R <- test[[2]]
  Y <- t(V) %*% x
  a <- t(U) %*% Y
  r <- Y - U %*% a
  xhat <- V %*% r + R %*% a
  phat <- R %*% a
  return(phat)
}

## Defining function to estimate periodic component
estimateTt <- function(x, epsilon, dT, nw, k, sigClip, progress=FALSE, freqIn=NULL) {
  
  ################################################################################
  # Algorithm step 1: spectrum/Ftest pilot estimate
  pilot <- spec.mtm(x, deltat=dT, nw=nw, k=k, Ftest=TRUE, plot=FALSE)
  
  if(is.null(freqIn)) {
    ################################################################################
    # Algorithm step 2: estimate significant peaks (sigClip)
    fmesh <- pilot$mtm$Ftest
    fsig <- fmesh > qf(sigClip, 2, pilot$mtm$k)
    floc <- which(fsig==TRUE)
    if(length(floc > 0)) {
      ###########################################################################   
      delta <- floc[2:length(floc)] - floc[1:(length(floc)-1)]
      if(length(which(delta==1)) > 0) {
        bad <- which(delta==1)
        if(!is.null(bad)) {
          if(progress) {
            for(j in 1:length(bad)) {
              cat(paste("Peak at ", formatC(pilot$freq[floc[bad[j]]], width=6, format="f"),
                        "Hz is smeared across more than 1 bin. \n", sep=""))
            } 
          }
        }
        floc <- floc[-bad] # eliminate the duplicates
      }
      
      ################################################################################
      # Algorithm step 3: estimate centers
      dFI <- pilot$freq[2]
      # epsilon <- 1e-10
      maxFFT <- 1e20
      max2 <- log(maxFFT, base=2)
      max3 <- log(maxFFT, base=3)
      max5 <- log(maxFFT, base=5)
      max7 <- log(maxFFT, base=7)
      
      freqFinal <- matrix(data=0, nrow=length(floc), ncol=1)
      
      for(j in 1:length(floc)) {
        if(progress) {
          cat(".")  
        }
        f0 <- pilot$freq[floc[j]]
        
        if(progress) {
          cat(paste("Optimizing Peak Near Frequency ", f0, "\n", sep=""))
        }
        
        # increasing powers of 2,3,5,7 on nFFT until peak estimate converges
        pwrOrig <- floor(log2(pilot$mtm$nFFT)) + 1
        fI <- f0
        converge <- FALSE
        
        for(k7 in 0:max7) {
          for(k5 in 0:max5) {
            for(k3 in 0:max3) {
              for(k2 in 1:max2) {
                
                if(!converge) {
                  nFFT <- 2^pwrOrig * 2^k2 * 3^k3 * 5^k5 * 7^k7
                  tmpSpec <- spec.mtm(x, deltat=dT, nw=5, k=8, plot=FALSE, Ftest=TRUE,
                                      nFFT=nFFT)
                  dF <- tmpSpec$freq[2]
                  f0loc <- which(abs(tmpSpec$freq - f0) <= dF)
                  range <- which(tmpSpec$freq <= (f0+1.1*dFI) & tmpSpec$freq >= (f0-1.1*dFI))
                  
                  fI2 <- tmpSpec$freq[which(tmpSpec$mtm$Ftest == max(tmpSpec$mtm$Ftest[range]))]
                  if(abs(fI - fI2) > epsilon) {
                    fI <- fI2
                  } else {
                    fF <- fI2
                    converge <- TRUE
                  }
                }
              }}}}
        freqFinal[j] <- fF
        if(progress) {
          cat(paste("Final frequency estimate: ", fF, "\n", sep=""))
        }
      }
      if(progress) {
        cat("\n")
      }
    } else {
      freqFinal <- NULL
      floc <- -1
    } # end of "there are freqs detected"
  } else {  # case where frequencies are already obtained
    freqFinal <- freqIn
    floc <- 1:length(freqFinal)
    if(length(freqFinal)==1 & freqFinal[1]==0) {
      floc <- -1
    }
  }
  ################################################################################
  # Algorithm step 4: frequencies obtained, estimate phase and amplitude
  #    by inverting the spectrum (i.e. line component removal)
  if(length(floc) > 1 | floc[1] > 0) {
    sinusoids <- matrix(data=0, nrow=length(x), ncol=length(floc))
    amp <- matrix(data=0, nrow=length(floc), ncol=1)
    phse <- matrix(data=0, nrow=length(floc), ncol=1)
    N <- length(x)
    t <- seq(1, N*dT, dT)
    
    for(j in 1:length(floc)) {
      sinusoids[, j] <- removePeriod(x, freqFinal[j], nw=5, k=8, deltaT=dT, warn=FALSE, prec=1e-10, sigClip=sigClip) 
      fit <- lm(sinusoids[, j] ~ sin(2*pi*freqFinal[j]*t) + cos(2*pi*freqFinal[j]*t) - 1)
      phse[j] <- atan(fit$coef[2] / fit$coef[1])
      amp[j] <- fit$coef[1] / cos(phse[j])
    }
    
    attr(sinusoids, "Phase") <- phse
    attr(sinusoids, "Amplitude") <- amp
    attr(sinusoids, "Frequency") <- freqFinal
    return(sinusoids)
  } else {
    sinusoids <- matrix(data=0, nrow=length(x), ncol=length(floc))
    attr(sinusoids, "Phase") <- 0
    attr(sinusoids, "Amplitude") <- 0
    attr(sinusoids, "Frequency") <- 0
    return(sinusoids)
  }
}

## Defining helper functions:
dpssap <- function(V, maxdeg) {
  
  # Sanity checks
  stopifnot(is.matrix(V), is.numeric(maxdeg), maxdeg>=0)
  N <- length(V[, 1])
  K <- length(V[1, ])
  P <- maxdeg + 1
  timeArr <- 1:N
  
  R <- matrix(data=0, nrow=N, ncol=P)
  U <- matrix(data=0, nrow=K, ncol=P)
  
  # Setup centered time index
  midTime <- (1+N) / 2
  scl <- 2/(N-1)
  timeArrC <- (timeArr - midTime) * scl
  
  # Start with Gegenbauer polynomials; convergence is faster
  alpha <- 0.75
  R[, 1] <- 1.0
  if(maxdeg > 0) {
    R[, 2] <- 2 * alpha * timeArrC
    if(maxdeg > 1) {
      for(j in 2:maxdeg) {
        A1 <- 2 * ( (j-1) + alpha ) / j
        A2 <- ( (j-2) + 2 * alpha ) / j
        
        R[, (j+1)] <- A1 * timeArrC * R[, j] - A2 * R[, (j-1)]
      } # end of loop on higher orders
    } # end of maxdeg > 1
  } # end of maxdeg > 0
  
  # Inner Products of R and V
  for(L in 1:P) {
    Kmin <- ( (L-1) %% 2 ) + 1
    for(k in seq(Kmin, K, 2)) {  # loop on non-zero Slepians
      U[k, L] <- t(V[, k]) %*% R[, L]
    }
  }
  
  # Degree 0, 1 (manual) -- L = degree+1
  for(L in 1:min(2,P)) {
    scl <- 1 / sqrt( sum(U[, L]^2) )
    U[, L] <- U[, L] * scl # orthonormalize
    R[, L] <- R[, L] * scl
  }
  
  # loop on higher degrees, applying Gram-Schmidt only on similar
  # parity functions (as even/odd are already orthogonal in U)
  if( P > 2 ) {
    for(L in 3:P) {
      if(L %% 2 == 0) {
        Kmin <- 2
      } else {
        Kmin <- 1
      }
      for(j in seq(Kmin, L-1, 2)) {
        scl <- sum( U[, L] * U[, j] )
        U[, L] <- U[, L] - scl * U[, j] # Gram-Schmidt
        R[, L] <- R[, L] - scl * R[, j]
      }
      scl <- 1 / sqrt(sum(U[, L]^2))
      U[, L] <- U[, L] * scl  # orthonormalize
      R[, L] <- R[, L] * scl
    }
  }
  
  Hn <- colSums(R^2)
  return(list(U,R,Hn))
}

removePeriod <- function(xd, f0, nw, k, deltaT, warn=FALSE, prec=1e-10, sigClip) {
  
  # xd : data
  # f0 : freq of periodicty to remove
  # nw, k : parameters of multitaper
  # deltaT : parameter of xd
  # prec.st : starting precision for finding a good nFFT for removal
  
  # check to make sure f0 is reasonable, otherwise warn
  N <- length(xd)
  spec.t <- spec.mtm(xd,nw=nw,k=k,Ftest=T,plot=F,nFFT=2^(floor(log(N,2))+2),deltat=deltaT)
  idx <- max(which(spec.t$freq < f0))
  if( max(spec.t$mtm$Ftest[idx],spec.t$mtm$Ftest[idx]) < qf(sigClip,2,(2*k-2)) && warn ) {
    warning("Ftest at frequency f0 not significant. Are you sure you want to remove this?")
  }
  
  # early parameter setup, find a nFFT that gives a bin *very* close to f0, or on top of it
  Nyq <- 1/2/deltaT
  nFFT <- -1
  prec.st <- prec
  while( nFFT < 0 ) {
    nFFT <- findPowers(N,f0,Nyq,prec.st)
    prec.st <- prec.st*10
  }
  
  spec <- spec.mtm(xd,nw=nw,k=k,returnInternals=T,Ftest=T,plot=F,nFFT=nFFT,maxAdaptiveIterations=0,
                   deltat=deltaT)
  
  # parameter setup
  w <- nw/N/deltaT
  df <- 1/nFFT/deltaT
  neh <- max(10,(floor((2*w)/df+1)))
  f0.idx <- seq(along=spec$freq)[spec$freq == (f0 - min(abs(spec$freq - f0))) | spec$freq == (f0 + min(abs(spec$freq - f0)))]
  
  ##########################################################################
  # 
  #  All spectral window work will require the full spectral array
  # 
  ##########################################################################
  # form spectral windows
  dw <- dpss(N,k,5.0)$v*sqrt(deltaT)
  # zero-pad
  dw.z <- rbind(dw,matrix(data=0,nrow=(spec$mtm$nFFT-N),ncol=k))
  # empty window array, nFFT x k
  sw <- matrix(data=0,nrow=spec$mtm$nFFT,ncol=k)
  for(j in 1:k) {
    ft <- fft(dw.z[,j])
    sw[,j] <- c(ft[(spec$mtm$nfreqs+1):spec$mtm$nFFT],ft[1:spec$mtm$nfreqs])
  }
  
  # form estimate of chosen frequency component - takes 0+/- neh from the spectral
  #   window and expands it by multiplying by the CMV at f0
  est <- matrix(data=complex(0,0),nrow=(2*neh+1),ncol=k)
  for(j in 1:k) {
    est[,j] <- spec$mtm$cmv[f0.idx]*(sw[((spec$mtm$nfreqs-1)-neh):((spec$mtm$nfreqs-1)+neh),j])
  }
  
  # subtract from original eigencoefficients
  egn <- spec$mtm$eigenCoefs
  egn <- rbind(Conj(egn[2:spec$mtm$nfreqs,]), egn)
  range <- (f0.idx-neh+spec$mtm$nfreqs) : (f0.idx+neh+spec$mtm$nfreqs)
  if(max(range) > nFFT) {
    # case of folding over the top, i.e. freq too close to Nyq+
    fold <- which(range > nFFT)
    rangeF <- range[fold]
    rangeN <- range[-fold]
    range <- c(1:length(rangeF), rangeN)
  } 
  est2 <- est
  for(j in 1:k) {
    est2[which(range < spec$mtm$nfreqs),j] <- Conj(est2[which(range < spec$mtm$nfreqs),j])
    egn[range,j] <- egn[range,j] - est2[,j]
  }
  
  blank <- matrix(data=0,nrow=nFFT,ncol=1)
  blank[f0.idx] <- spec$mtm$cmv[f0.idx]
  blank[nFFT-f0.idx+2] <- Conj(spec$mtm$cmv[f0.idx])
  inv <- fft(blank,inverse=T)
  inv <- Re(inv)[1:N]
  
  #  cat(paste("Freq: ", spec$freq[f0.idx]," \n",
  #            "Amp : ", sqrt(Mod(spec$mtm$cmv[f0.idx])), "\n",
  #            "Phse: ", Arg(spec$mtm$cmv[f0.idx]), "\n", sep=""))
  return(inv)
}

findPowers <- function(N,f0,Nyq,prec) {
  nFFT <- 1e30
  
  low2 <- 0
  high2 <- floor(log(N,2))+2
  low3 <- 0
  high3 <- floor(log(N,3))+2
  low5 <- 0
  high5 <- floor(log(N,5))+2
  low7 <- 0
  high7 <- floor(log(N,7))+2
  for(i in low2:high2) {
    for(j in low3:high3) {
      for(k in low5:high5) {
        for(l in low7:high7) {
          att <- 2^i * 3^j * 5^k * 7^l
          if((att > 2*N) & att < 100*N) {
            df <- (Nyq*2)/att
            if( abs(trunc(f0/df)*df - f0) < prec ) {
              if(att < nFFT) {
                nFFT <- att 
              }
            }
          } # big enough
        } # end of 7
      } # end of 5
    } # end of 3
  } # end of 2
  if(nFFT == 1e30) {
    return(-1)
  } else {
    return(nFFT)
  }
}


## Defining main method
## -----------------------


#' main
#' 
#' Function that works through the designed algorithm and calls functions in order.
#' @param x0 {list}; List object containing the original incomplete time series
#' @param max_iter {integer}; Maximum number of iterations of the algorithm to perform
#' @param n_series {integer}; Number of new time series to construct
#' @param p {flaot}; Proportion of missing data to be applied to the simulated series
#' @param g {integer}; Gap width of missing data to be applied to the simulated series
#' @param K {integer}; Number of output series with a unique gap structure for each simulated series
#' @param var {float}; Variance for perturbations
#'
main <- function(x0, max_iter, n_series, p, g, K, var){
  
  results = matrix(NA, ncol = length(x0), nrow = max_iter) ## Defining matrix to store results
  xI = initialize(x0) ## Step 1
  
  for (i in 1:max_iter){
    x_est = estimator(xI) ## Step 2
    data = simulator(x_est, n_series, var, p, g, K); inputs = data[[1]]; targets = data[[2]] ## Steps 3/4
    pred = impute(x0, inputs, targets) ## Step 5
    xI = ifelse(is.na(x0), pred, x0); results[i,] = xI ## Step 6
    print(paste0('Interation ', i))
  }
  return(colMeans(results))
}
```

## Algorithm:
1. Interpolate missing values in the original time series using linear interpolation.
2. a. Estimate the trend component of the input time series
   b. Estimate the periodic component(s) of the input time series
3. Simulate a sufficient number of time series with the same trend and periodic structure by applying small perturbations to the residual noise in the frequency domain representation (will become neural network targets). 
4. Impose a gap structure on the simulated time series (i.e., the same gap structure as observed in the original time series) and produce K unique ‘gappy’ time series (will become neural network inputs).
5. Construct, compile, and fit a neural network 'autoencoder' model using the newly created input and target time series. Using the autoencoder, predict on the original time series.
6. Extract the predicted values of the missing data points to complete the original time series. 
7. Repeat steps 2-6 using the output of Step 6 as the input for Step 2, each time storing the predictions.
8. Return the final predictions as the average prediction over the total number of specified iterations. 

\newpage

## Setup Steps:

The Neural Network Imputer relies on these four libraries specifically:

```{r setup2, message = FALSE}
library(tsinterp)
library(interpTools)
library(tensorflow)
library(keras)
```

We can simulate a time series and go through the algorithm to visualize what is happening in each step of the process. 

```{r setup3, message = FALSE, warning=FALSE, fig.align='center', fig.dim=c(8,5), echo=FALSE}
## Defining the time series for demo
set.seed(42)
xt = simXt(N = 100, mu = 0, numTrend = 1, numFreq = 2)$Xt
xt = (xt - min(xt)) / (max(xt) - min(xt))
x_gapped = simulateGaps(list(xt), p = 0.1, g = 1, K = 1)
x_gappy = x_gapped[[1]]$p0.1$g1[[1]]
plot(xt, type = 'l', main = 'Original Time Series', xlab = 'Time', ylab = 'X', lwd = 2); grid()
lines(which(is.na(x_gappy)), xt[is.na(x_gappy)], type = 'p', col = 'black', pch = 21, bg = 'red')
legend('topleft', legend = c('Missing Data Point'), col = 'red', pch = 16, cex = 1.2)
```

\newpage

## Initialization Step:

The first step of the algorithm is to use linear imputation to fill in the gaps for the original input time series.

```{r demo1, fig.align='center', fig.dim=c(8,5), echo = FALSE}
step_1_demo <- function(x0){
  xI = initialize_demo(x0)
  
  plot(xI, type = 'l', main = 'Original Time Series w/ Linear Imp.', xlab = 'Time', ylab = 'X', col = 'red', lwd = 1)
  lines(xt, type = 'l', lwd = 2); grid()
  lines(which(is.na(x_gappy)), xt[is.na(x_gappy)], type = 'p', col = 'black', pch = 21, bg = 'red')
  legend('topleft', legend = c('Missing Data Point', 'Linear Imp.'), col = c('red', 'red'), 
         cex = 1.2, lty = c(NA, 1), pch = c(16, NA))

  return(xI)
}
step1 = step_1_demo(x_gappy)
```

\newpage

## Trend and Periodic Estimation:

The next step of the algorithm is to use functions from the TSinterp package to estimate the trend and periodic components of the input time series. This step returns the trend + periodic series, as well as the residual noise. 

```{r demo2, fig.align='center', fig.dim=c(8,9), echo=FALSE}
step_2_demo <- function(xI){
  x_est = estimator_demo(xI)
  Mt = x_est[[1]]; Tt = x_est[[2]]; Xt = x_est[[3]]
  
  par(mfrow = c(2,1))
  plot(xI, type = 'l', main = 'Estimated Trend + Periodic', xlab = 'Time', ylab = 'X', lwd = 2)
  lines(Xt, type = 'l', col = 'dodgerblue', lty = 1, lwd = 1); grid()
  legend('topleft', legend = c('Linear Imp.', 'Trend + Periodic'), lty = 1, 
         lwd = 2, col = c('black', 'dodgerblue'), cex = 1.2)
  
  plot(xI - Xt, type = 'l', col = 'darkorange', lwd = 2, main = 'Residual Noise', ylab = 'W', xlab = 'Time')
  grid()
  return(list(Xt, xI - Xt))
}
step2 = step_2_demo(step1)
step2_x = step2[[1]]
step2_w = step2[[2]]
```

\newpage

## Time Series Simulation:

The next steps are to generate an appropriate number of time series with the same trend and periodic structure by applying small perturbations to the residual noise in the frequency domain and then inverting it back into the time domain. Next, we impose a gap structure similar to that of the original input time series. The gap structure is the same, but there is a parameter which indicates whether or not the placement of the gaps is randomized. 

```{r demo3, fig.align='center', fig.dim=c(8,9), echo = FALSE}
step_3_4_demo <- function(x0, xI, x, w){
  
  options(warn=-1)
  step3 = simulator_demo(x0, x, w, n_series = 2, p = 0.1, g = 1, K = 1, random = TRUE)
  inputs = step3[[1]]; targets = step3[[2]]
  
  par(mfrow = c(2,1))
  plot(xI, type = 'l', main = 'Simulated Time Series (Random = TRUE)', xlab = 'Time', ylab = 'X', lwd = 2); grid()
  lines(which(is.na(x_gappy)), xI[is.na(x_gappy)], type = 'p', col = 'black', pch = 21, bg = 'black')

  lines(targets[1,], type = 'l', col = 'green', lwd = 0.5)
  lines(which(is.na(inputs[1,])), targets[1, is.na(inputs[1,])], type = 'p', col = 'black', 
        pch = 21, bg = 'green', cex = 0.7)
  
  lines(targets[2,], type = 'l', col = 'red', lwd = 0.5)
  lines(which(is.na(inputs[2,])), targets[2, is.na(inputs[2,])], type = 'p', col = 'black', 
        pch = 21, bg = 'red', cex = 0.7)
  
  legend('topleft', legend = c('Linear Imp.', 'Simulated', 'Simulated', 'Missing Index'), 
         lty = c(1, 1, 1, NA), pch = c(NA, NA, NA, 1), cex = 1, lwd = c(2, 2, 2, 2),
         col = c('black', 'green', 'red', 'black'))
  
  
  
  

  step3 = simulator_demo(x0, x, w, n_series = 2, p = 0.1, g = 1, K = 1, random = FALSE)
  inputs = step3[[1]]; targets = step3[[2]]
  
  plot(xI, type = 'l', main = 'Simulated Time Series (Random = FALSE)', xlab = 'Time', ylab = 'X', lwd = 2); grid()
  lines(which(is.na(x_gappy)), xI[is.na(x_gappy)], type = 'p', col = 'black', pch = 21, bg = 'black')

  lines(targets[1,], type = 'l', col = 'green', lwd = 0.5)
  lines(which(is.na(inputs[1,])), targets[1, is.na(inputs[1,])], type = 'p', col = 'black', 
        pch = 21, bg = 'green', cex = 0.7)
  
  lines(targets[2,], type = 'l', col = 'red', lwd = 0.5)
  lines(which(is.na(inputs[2,])), targets[2, is.na(inputs[2,])], type = 'p', col = 'black', 
        pch = 21, bg = 'red', cex = 0.7)
  
  legend('topleft', legend = c('Linear Imp.', 'Simulated', 'Simulated', 'Missing Index'), 
         lty = c(1, 1, 1, NA), pch = c(NA, NA, NA, 1), cex = 1, lwd = c(2, 2, 2, 2),
         col = c('black', 'green', 'red', 'black'))
  
  return(list(inputs, targets))
}

step3_4 = step_3_4_demo(x_gappy, step1, step2_x, step2_w)
```

\newpage

## Noise Perturbation Process:

1. Subtract the estimated trend + periodic series from the linear imputed series to form the residual noise series.

2. Convert the residual noise series to the frequency domain using the fft() function.

3. The output of the fft() function is a vector of complex numbers with length $N$. To perform the perturbation, generate another vector of length $N$ with complex values of amplitude 1 and phase somewhere between $(0, 2 \pi)$.

4. Multiply the two complex vectors. This applies a small perturbation to the original residual noise in the frequency domain.

5. Convert the output of Step 4 back into the time domain and add it to the trend + periodic series. 

6. This has created one time series which will be an element of the neural network training data. Repeat this process enough times as to generate a sufficient set of training data. 

\newpage

```{r noise_process, fig.align='center', fig.dim=c(8,8)}

## Generate a time series
Xt = simXt(N = 100, mu = 0, numTrend = 0, numFreq = 2)$Xt

## Estimate trend + periodic and noise components
estimate = estimator_demo(Xt)
Mt = estimate[[1]]; Tt = estimate[[2]]; Wt = Xt - Mt - Tt;

## Converting the residual noise series to the frequency domain
Wt_freq = fft(Wt)
```

```{r noise_processb, fig.align='center', fig.dim=c(8,8), echo = FALSE}
## Plotting the residual noise and frequency
par(mfrow = c(2,1))
plot(0:99, Wt, type = 'l', col = 'darkorange', lwd = 2, main = 'Residual Noise', 
     ylab = 'Wt', xlab = 'Time'); grid()
plot(0:99, Mod(Wt_freq) / length(Wt), type='h', lwd = 4, xlab = 'Frequency', ylab = 'Amplitude', 
     main = 'Frequency (FFT Transform)'); grid()
```

\newpage

```{r noise_processc}
## Generating new vector and multiplying the two complex vectors 
Wt_freq_p = Wt_freq * complex(modulus = runif(100, 0.98, 1.02), argument = runif(100, -pi/6, -pi/6))

## Converting perturbation back into time domain
Wt_p = fft(Wt_freq_p, inverse = TRUE) / length(Wt)
```

```{r noise_processd, fig.align='center', fig.dim=c(8,5), echo = FALSE}
## Plotting the residual noise and frequency
par(mfrow = c(1,1))
plot(0:99, Wt, type = 'l', col = 'darkorange', lwd = 2, main = 'Noise in Time Domain', 
     ylab = 'Wt', xlab = 'Time', ylim = c(-0.5, 0.5)); grid()
lines(0:99, Wt_p, type = 'l', lwd = 1, col = 'dodgerblue4'); grid()
legend('topleft', legend = c('Residual Noise', 'Perturbed Noise'), lty = 1, cex = 1, lwd = 2,
         col = c('darkorange', 'dodgerblue4'))
```

\newpage

```{r noise_processe}
## Adding the perturbed noise to the trend and periodic estimations
Xt_p = Mt + Tt + Wt_p
```

```{r noise_processf, fig.align='center', fig.dim=c(8,5), echo = FALSE}
plot(0:99, Xt, type = 'l', col = 'black', lwd = 2, main = 'Final Simulation of One Input Series', 
     ylab = 'Xt', xlab = 'Time', ylim = c(-1, 1)); grid()
lines(0:99, Xt_p, type = 'l', lwd = 1, col = 'chartreuse3')
legend('topleft', legend = c('Original', 'Simulated'), lty = 1, cex = 1, lwd = 2,
         col = c('black', 'chartreuse3'))
```
